

1)import numpy as np (es opÃ©rations numÃ©riques)
import matplotlib.pyplot as pl  (la visualisation)
import pandas as pd (la manipulation des donnÃ©es.)



2)df = pd.read_csv('E:/univ/APM/apm tp/tp1partie2 et 3fichier important house de la prof/house.txt')

( Cette ligne lit un fichier CSV ('house.txt') et stocke les donnÃ©es dans un DataFrame Pandas appelÃ© `df`)
( donc house.txt dans variable df stockÃ©e dans le data frame )


1. df.to_csv('./house.csv', index=False): Cette ligne prend le DataFrame df, qui a Ã©tÃ© crÃ©Ã© en lisant le fichier CSV initial (house.txt), et le sauvegarde dans un nouveau fichier CSV (house.csv). L'argument index=False signifie que les indices de ligne ne seront pas inclus dans le fichier CSV gÃ©nÃ©rÃ©.
2. features=['area','bedrooms','floors','age','price']: Cette ligne crÃ©e une liste appelÃ©e features qui contient les noms des colonnes que vous souhaitez attribuer Ã  votre DataFrame lors de la lecture du fichier CSV. 
3. house = pd.read_csv('./house.csv', names=features) le DataFrame house est crÃ©Ã© avec des colonnes nommÃ©es 'area', 'bedrooms', 'floors', 'age', et 'price'.
4. house.head(): Cette ligne affiche les premiÃ¨res lignes du DataFrame house Ã  des fins de vÃ©rification. 




5)
X=house.iloc[:,:4]
y=house.iloc[:,4]


- Ces lignes divisent le DataFrame `house` en deux parties : `X` contient les caractÃ©ristiques (les quatre premiÃ¨res colonnes), et `y` contient les Ã©tiquettes (la cinquiÃ¨me colonne).


6)
X.head()

y.head()

ne mÃ©thode de la bibliothÃ¨que pandas, appliquÃ©e Ã  un objet de type DataFrame. Elle est utilisÃ©e pour afficher les premiÃ¨res lignes d'un DataFrame.


7)

X=np.array(X)
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=1/3,random_state=0)

 convertit la structure de donnÃ©es X en un tableau NumPy. 


 en utilisant la fonction `train_test_split` de scikit-learn.

â€¢ X : Cela reprÃ©sente les caractÃ©ristiques du jeux de donnees.
â€¢ y : Cela reprÃ©sente la variable cible que vous essayez de prÃ©dire.
La fonction train_test_split prend les caractÃ©ristiques X et la variable cible y et les divise en quatre ensembles :
â€¢ X_train : C'est le sous-ensemble des caractÃ©ristiques utilisÃ© pour entraÃ®ner le modÃ¨le.
â€¢ X_test : C'est le sous-ensemble des caractÃ©ristiques utilisÃ© pour tester le modÃ¨le.
â€¢ y_train : C'est la variable cible correspondante pour l'entraÃ®nement du modÃ¨le.
â€¢ y_test : C'est la variable cible correspondante pour les tests du modÃ¨le.

Les paramÃ¨tres de la fonction train_test_split sont les suivants :
â€¢ test_size=1/3 : Cela spÃ©cifie que 1/3 (environ 33%) des donnÃ©es seront utilisÃ©es pour le test, et le reste (environ 67%) sera utilisÃ© pour l'entraÃ®nement.
â€¢ random_state=0 : Cela fixe la graine du gÃ©nÃ©rateur de nombres alÃ©atoires, assurant ainsi que la division des donnÃ©es reste la mÃªme Ã  chaque exÃ©cution du code. Cela garantit la reproductibilitÃ© des rÃ©sultats.

8) Prediction:


def prediction(X, a):
    y_hat = np.dot(X, a)
    return y_hat

# testing of this function : 
X_t =np.array([[1., 5.],[1., 10.],[1., 8]])
theta_t = np.array([0.25,0.5])
a=prediction(X_t,theta_t)
print(X_t)
print(theta_t)
print(a)


- Cette fonction `prediction` prend les donnÃ©es `X`
les caractÃ©ristiques d'un ensemble de donnÃ©es
 et les paramÃ¨tres du vecteur `a`
paramÃ¨tres d'un modÃ¨le de rÃ©gression linÃ©aire
 pour calculer les prÃ©dictions `y_hat` en utilisant la multiplication matricielle avec .dot 
Retourner y_hat
Creee un tableau de donne x diviser en 3 tableaux diff
CrÃ©er tableau theta 
Faire prediction dans var a qui est la multiplication des deux matrices et vecteur 
affiche les tableaux de x
Puis de theta 
Puis la multiplication a


9)fonction cout 

Le modÃ¨le de rÃ©gression linÃ©aire simple

Valeur observÃ©e y=a0+a1*xi+ğœ€ğ‘–
valeur prÃ©dite ğ‘¦_hat = ğ‘0_hat +a1_hat*xi
Erreur de predication ğœ€ğ‘– = ğ‘¦ğ‘– âˆ’ ğ‘¦_hat
(ğœ€ğ‘–)*2 =( ğ‘¦ğ‘– âˆ’ ğ‘¦_hat)*2
(ğœ€ğ‘–)*2 =( ğ‘¦ğ‘– âˆ’(ğ‘0_hat +a1_hat*xi))*2

Fonction cout 






def J(X, Y, a):
    y_hat = prediction(X, a)        ( apl a la fonction prediction  precedente )
    J = np.mean((Y - y_hat)**2) / 2       ( calculer fonction cout  avec Np.mean calcule la moyenne de tout les ğœ€ğ‘– au carrÃ© de i Ã  n)
    return J                                             (retourne le cout )



# Test de la fonction coÃ»t avec des donnÃ©es d'exemple
X_t = np.array([[1., 5.], [1., 10.], [1., 8.]])
Y_t = np.array([3., 5., 4.5])
a = np.array([0.25, 0.5])
cost = J(X_t, Y_t, theta_t)
print(cost)



10)### III-7. Calcul des dÃ©rivÃ©es partielles





#todo
# ecrire la fonction derivees qui calcule les dÃ©rivÃ©es partielles par rapport Ã  chaque parametre du modÃ¨le
def derivees_partielles(X, Y, a):        (nouvelle fonction derivee )
  """
  Calculer  derivÃ©es paertielles.
    
  Args:
    X (ndarray : Data, n examples 
    Y (ndarray): Label, n labels   
    a          : model parameters  
  
  Returns
      derivees
  """
  
  erreur = (Y - prediction(X, a))                  (ğœ€ğ‘– = ğ‘¦ğ‘– âˆ’ ğ‘¦_hat) en utilisant la fonction prediction

  # dÃ©rivÃ©es -1/len(y) le mean est dans la fonction predicition  * on a yi_y_hat qui est l erreur multiplier par la matrice Xi qui est apl X.T
  derivees = -(1 / len(Y)) * np.dot(X.T, erreur)
  return derivees 

# Test de la fonction dÃ©rivÃ©es avec des donnÃ©es d'exemple
X_t = np.array([[1., 5.], [1., 10.], [1., 8]])
theta_t = np.array([0.25, 0.5])
Y_t = np.array([3., 5., 4.5])
print("rÃ©sultats:", derivees_partielles(X_t, Y_t, theta_t))


11)### III-8.  l'algorithme de descente de gradient


